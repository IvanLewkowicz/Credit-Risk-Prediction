{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6e86bc6",
   "metadata": {},
   "source": [
    "# Intro\n",
    "En este notebook ya dejo presentado el modelo final a usar que luego ira a parar a .py _train.py_ y _predict.py_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15dd2932",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a09e4fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import uniform, randint\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from xgboost import XGBClassifier, plot_importance\n",
    "from joblib import dump\n",
    "import shap\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    confusion_matrix,\n",
    "    average_precision_score,\n",
    "    classification_report,\n",
    "    RocCurveDisplay,\n",
    "    PrecisionRecallDisplay\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4df2da9",
   "metadata": {},
   "source": [
    "# Funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f621f874",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test(X,y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, stratify=y, random_state=42\n",
    "    )\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def get_pos_weight(y_train):\n",
    "    # Calculate class imbalance ratio\n",
    "    neg, pos = np.bincount(y_train)\n",
    "    scale_pos_weight = neg / pos\n",
    "    print(f\"Class ratio: {neg}:{pos}, scale_pos_weight = {scale_pos_weight:.2f}\")\n",
    "    \n",
    "    return scale_pos_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9fab8589",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_train_test_report(name,model,params,X_train,X_test,y_train,y_test,cv):\n",
    "    print(f\"\\n>>> Training {name} ...\")\n",
    "\n",
    "    search = RandomizedSearchCV(\n",
    "        estimator=model,\n",
    "        param_distributions=params,\n",
    "        scoring='average_precision',\n",
    "        n_iter=25,              \n",
    "        cv=cv,\n",
    "        n_jobs=-1,\n",
    "        random_state=42,\n",
    "        verbose=3\n",
    "    )\n",
    "\n",
    "    search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "    # Evaluate best model\n",
    "    best_model = search.best_estimator_\n",
    "    best_parameter = search.best_params_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    y_prob = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    metrics = {\n",
    "        'model': name,\n",
    "        'best_params': search.best_params_,\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'precision': precision_score(y_test, y_pred, zero_division=0),\n",
    "        'recall': recall_score(y_test, y_pred),\n",
    "        'f1': f1_score(y_test, y_pred),\n",
    "        'roc_auc': roc_auc_score(y_test, y_prob),\n",
    "        'pr_auc': average_precision_score(y_test,y_prob)\n",
    "    }\n",
    "\n",
    "    print(f\"Classification report for {name}:\\n\", classification_report(y_test, y_pred))\n",
    "    \n",
    "    return best_model,best_parameter,metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab861826",
   "metadata": {},
   "source": [
    "# Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9f1db88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../data/raw/cs-training.csv\")\n",
    "X = df_train.drop(['SeriousDlqin2yrs','Unnamed: 0','age','NumberOfDependents','DebtRatio','MonthlyIncome','NumberOfOpenCreditLinesAndLoans','NumberRealEstateLoansOrLines'],axis = 1)\n",
    "y = df_train['SeriousDlqin2yrs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2bb9148e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = get_train_test(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0116c8d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57836     0\n",
       "132895    0\n",
       "27981     0\n",
       "37852     0\n",
       "103813    0\n",
       "         ..\n",
       "18048     0\n",
       "3895      0\n",
       "109980    0\n",
       "74354     0\n",
       "80530     0\n",
       "Name: SeriousDlqin2yrs, Length: 120000, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd0d23b",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e6916e",
   "metadata": {},
   "source": [
    "## Model initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c4ebf8fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class ratio: 111979:8021, scale_pos_weight = 13.96\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier(\n",
    "                eval_metric='logloss',\n",
    "                random_state=42,\n",
    "                scale_pos_weight=get_pos_weight(y_train)\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1370eb39",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e6fab734",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distributions = {\n",
    "                'n_estimators': randint(100, 600),\n",
    "                'max_depth': randint(3, 10),\n",
    "                'learning_rate': uniform(0.01, 0.3),\n",
    "                'subsample': uniform(0.6, 0.4),\n",
    "                'colsample_bytree': uniform(0.6, 0.4),\n",
    "                'min_child_weight': randint(1, 10),\n",
    "                'gamma': uniform(0, 5),\n",
    "                'reg_lambda': uniform(0, 5),\n",
    "                'reg_alpha': uniform(0, 5),\n",
    "                'base_score': uniform(0.1,0.8)\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e37889",
   "metadata": {},
   "source": [
    "## Train setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0b678708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Training final_xgboost_model ...\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "Classification report for final_xgboost_model:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.76      0.86     27995\n",
      "           1       0.19      0.79      0.31      2005\n",
      "\n",
      "    accuracy                           0.76     30000\n",
      "   macro avg       0.59      0.78      0.58     30000\n",
      "weighted avg       0.93      0.76      0.82     30000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "name = 'final_xgboost_model'\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "best_model,best_params,metrics = generate_train_test_report(name,model,param_distributions,X_train, X_test, y_train, y_test,cv)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4e15bc6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'final_xgboost_model',\n",
       " 'best_params': {'base_score': np.float64(0.7793787283953424),\n",
       "  'colsample_bytree': np.float64(0.8630451569201374),\n",
       "  'gamma': np.float64(2.841543016677358),\n",
       "  'learning_rate': np.float64(0.038102430348427745),\n",
       "  'max_depth': 5,\n",
       "  'min_child_weight': 6,\n",
       "  'n_estimators': 474,\n",
       "  'reg_alpha': np.float64(1.2523090930279208),\n",
       "  'reg_lambda': np.float64(2.9493542378027193),\n",
       "  'subsample': np.float64(0.9915571433100037)},\n",
       " 'accuracy': 0.7638666666666667,\n",
       " 'precision': 0.1921445023639229,\n",
       " 'recall': 0.7905236907730673,\n",
       " 'f1': 0.30914764969767894,\n",
       " 'roc_auc': 0.8559003901213211,\n",
       " 'pr_auc': 0.38764139104925116}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a50b6de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(best_model,data=X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4bbff291",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shap\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    StratifiedKFold,\n",
    "    RandomizedSearchCV\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    average_precision_score,\n",
    "    classification_report,\n",
    ")\n",
    "\n",
    "\n",
    "class ModelTrainer:\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_path: str,\n",
    "        drop_columns: str,\n",
    "        target: str,\n",
    "        model_params: dict,\n",
    "        model_path: str,\n",
    "        explainer_path: str,\n",
    "        model_name: str\n",
    "    ):\n",
    "        self.data_path = data_path\n",
    "        self.drop_columns = drop_columns\n",
    "        self.target = target\n",
    "        self.model_params = model_params\n",
    "        self.model_path = model_path\n",
    "        self.explainer_path = explainer_path\n",
    "        self.model_name = model_name\n",
    "\n",
    "        # internal variables\n",
    "        self.df = None\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "        self.X_train = None\n",
    "        self.X_test = None\n",
    "        self.y_train = None\n",
    "        self.y_test = None\n",
    "        self.best_model = None\n",
    "        self.best_params = None\n",
    "        self.metrics = None\n",
    "\n",
    "\n",
    "    # ----------------------------------------------------------\n",
    "    # LOAD + PREPARE DATA\n",
    "    # ----------------------------------------------------------\n",
    "    def load_data(self):\n",
    "        self.df = pd.read_csv(self.data_path)\n",
    "        self.X = self.df.drop(columns=self.drop_columns)\n",
    "        self.y = self.df[self.target]\n",
    "        print(f\"Loaded dataset: {self.df.shape} rows\")\n",
    "\n",
    "\n",
    "    def prepare_data(self):\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n",
    "            self.X,\n",
    "            self.y,\n",
    "            test_size=0.2,\n",
    "            stratify=self.y,\n",
    "            random_state=42\n",
    "        )\n",
    "        print(\"Data prepared:\")\n",
    "        print(f\" - Train shape: {self.X_train.shape}\")\n",
    "        print(f\" - Test shape: {self.X_test.shape}\")\n",
    "        print(f\" - Y Train shape: {self.y_train.shape}\")\n",
    "        print(f\" - Y Test shape: {self.y_test.shape}\")\n",
    "\n",
    "\n",
    "    # ----------------------------------------------------------\n",
    "    # UTILS\n",
    "    # ----------------------------------------------------------\n",
    "    def get_pos_weight(self):\n",
    "        y_arr = np.asarray(self.y_train).astype(int).reshape(-1)\n",
    "        neg, pos = np.bincount(y_arr)\n",
    "        w = neg / pos\n",
    "        print(f\"Class ratio {neg}:{pos}, scale_pos_weight = {w:.2f}\")\n",
    "        return w\n",
    "\n",
    "\n",
    "    # ----------------------------------------------------------\n",
    "    # TRAIN\n",
    "    # ----------------------------------------------------------\n",
    "    def train(self):\n",
    "        print(f\"\\n>>> Training {self.model_name} ...\")\n",
    "\n",
    "        model = XGBClassifier(\n",
    "            eval_metric='logloss',\n",
    "            random_state=42,\n",
    "            scale_pos_weight=self.get_pos_weight()\n",
    "        )\n",
    "\n",
    "        cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "        search = RandomizedSearchCV(\n",
    "            estimator=model,\n",
    "            param_distributions=self.model_params,\n",
    "            scoring='average_precision',\n",
    "            n_iter=25,\n",
    "            cv=cv,\n",
    "            n_jobs=-1,\n",
    "            random_state=42,\n",
    "            verbose=3,\n",
    "        )\n",
    "\n",
    "        search.fit(self.X_train, self.y_train)\n",
    "\n",
    "        self.best_model = search.best_estimator_\n",
    "        self.best_params = search.best_params_\n",
    "        print(\"Best parameters:\", self.best_params)\n",
    "\n",
    "\n",
    "    # ----------------------------------------------------------\n",
    "    # EVALUATE\n",
    "    # ----------------------------------------------------------\n",
    "    def evaluate(self):\n",
    "        y_pred = self.best_model.predict(self.X_test)\n",
    "        y_prob = self.best_model.predict_proba(self.X_test)[:, 1]\n",
    "\n",
    "        self.metrics = {\n",
    "            \"model\": self.model_name,\n",
    "            \"best_params\": self.best_params,\n",
    "            \"accuracy\": accuracy_score(self.y_test, y_pred),\n",
    "            \"precision\": precision_score(self.y_test, y_pred, zero_division=0),\n",
    "            \"recall\": recall_score(self.y_test, y_pred),\n",
    "            \"f1\": f1_score(self.y_test, y_pred),\n",
    "            \"roc_auc\": roc_auc_score(self.y_test, y_prob),\n",
    "            \"pr_auc\": average_precision_score(self.y_test, y_prob),\n",
    "        }\n",
    "\n",
    "        print(\"\\nClassification Report:\\n\")\n",
    "        print(classification_report(self.y_test, y_pred))\n",
    "\n",
    "        print(\"\\nMetrics:\")\n",
    "        for k, v in self.metrics.items():\n",
    "            print(f\"{k}: {v}\")\n",
    "\n",
    "        return self.metrics\n",
    "\n",
    "\n",
    "    # ----------------------------------------------------------\n",
    "    # SAVE ARTIFACTS\n",
    "    # ----------------------------------------------------------\n",
    "    def save(self):\n",
    "        # SHAP Explainer\n",
    "        explainer = shap.TreeExplainer(self.best_model)\n",
    "\n",
    "        # Save full training artifact\n",
    "        artifact = {\n",
    "            \"model\": self.best_model,\n",
    "            \"features\": list(self.X_train.columns),\n",
    "            \"params\": self.best_params,\n",
    "            \"metrics\": self.metrics\n",
    "        }\n",
    "\n",
    "        joblib.dump(artifact, self.model_path)\n",
    "        joblib.dump(explainer, self.explainer_path)\n",
    "\n",
    "        print(f\"\\nModel saved to {self.model_path}\")\n",
    "        print(f\"Explainer saved to {self.explainer_path}\")\n",
    "\n",
    "\n",
    "    # ----------------------------------------------------------\n",
    "    # FULL PIPELINE\n",
    "    # ----------------------------------------------------------\n",
    "    def run(self):\n",
    "        self.load_data()\n",
    "        self.prepare_data()\n",
    "        self.train()\n",
    "        self.evaluate()\n",
    "        #self.save()\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# RUN SCRIPT\n",
    "# ----------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    param_distributions = {\n",
    "                'n_estimators': randint(100, 600),\n",
    "                'max_depth': randint(3, 10),\n",
    "                'learning_rate': uniform(0.01, 0.3),\n",
    "                'subsample': uniform(0.6, 0.4),\n",
    "                'colsample_bytree': uniform(0.6, 0.4),\n",
    "                'min_child_weight': randint(1, 10),\n",
    "                'gamma': uniform(0, 5),\n",
    "                'reg_lambda': uniform(0, 5),\n",
    "                'reg_alpha': uniform(0, 5),\n",
    "                'base_score': uniform(0.1,0.8)\n",
    "            }\n",
    "\n",
    "    trainer = ModelTrainer(\n",
    "        data_path=\"../data/raw/cs-training.csv\",\n",
    "        drop_columns=['SeriousDlqin2yrs','Unnamed: 0'],\n",
    "        target=['SeriousDlqin2yrs'],\n",
    "        model_params=param_distributions,\n",
    "        model_path=\"../models/xgb_model.joblib\",\n",
    "        explainer_path=\"../models/xgb_shap_explainer.joblib\",\n",
    "        model_name=\"XGBoost_Model\"\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a8665e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset: (150000, 12) rows\n",
      "Data prepared:\n",
      " - Train shape: (120000, 10)\n",
      " - Test shape: (30000, 10)\n",
      " - Y Train shape: (120000, 1)\n",
      " - Y Test shape: (30000, 1)\n",
      "\n",
      ">>> Training XGBoost_Model ...\n",
      "Class ratio 111979:8021, scale_pos_weight = 13.96\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "Best parameters: {'base_score': np.float64(0.7682419964713904), 'colsample_bytree': np.float64(0.7283120259886944), 'gamma': np.float64(0.9325925519992712), 'learning_rate': np.float64(0.022232542466429174), 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 502, 'reg_alpha': np.float64(3.555747662190089), 'reg_lambda': np.float64(4.047505230698577), 'subsample': np.float64(0.7394663949166917)}\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.81      0.89     27995\n",
      "           1       0.23      0.76      0.35      2005\n",
      "\n",
      "    accuracy                           0.81     30000\n",
      "   macro avg       0.60      0.79      0.62     30000\n",
      "weighted avg       0.93      0.81      0.85     30000\n",
      "\n",
      "\n",
      "Metrics:\n",
      "model: XGBoost_Model\n",
      "best_params: {'base_score': np.float64(0.7682419964713904), 'colsample_bytree': np.float64(0.7283120259886944), 'gamma': np.float64(0.9325925519992712), 'learning_rate': np.float64(0.022232542466429174), 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 502, 'reg_alpha': np.float64(3.555747662190089), 'reg_lambda': np.float64(4.047505230698577), 'subsample': np.float64(0.7394663949166917)}\n",
      "accuracy: 0.8106\n",
      "precision: 0.22653577272051167\n",
      "recall: 0.7596009975062344\n",
      "f1: 0.3489917506874427\n",
      "roc_auc: 0.8678978121761145\n",
      "pr_auc: 0.40266481876285326\n"
     ]
    }
   ],
   "source": [
    "trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5bfa2772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model saved to ../models/xgb_model.joblib\n",
      "Explainer saved to ../models/xgb_shap_explainer.joblib\n"
     ]
    }
   ],
   "source": [
    "trainer.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "credit-risk-prediction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
